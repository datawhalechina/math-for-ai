<center><big><font color="red">本教程由 <a href="https://github.com/datawhalechina/math-for-ai">Datawhale 开源社区</a>编译，与对应的英文原版均开源免费</font></big></center>

## 9.4 最大似然作为正交投影

在经过大量代数运算推导出最大似然估计和MAP估计之后，我们现在将为最大似然估计提供一个几何解释。让我们考虑一个简单的线性回归设置：

 $$
y = x \theta + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2) \tag{9.65}
$$

其中，我们考虑从原点通过的线性函数  $ f: \mathbb{R} \to \mathbb{R} $ （为了清晰起见，这里省略了特征）。参数  $ \theta $  决定了直线的斜率。图9.12(a)展示了一个一维数据集。给定一个训练数据集  $ \{(x_1, y_1), \ldots, (x_N, y_N)\} $ ，回忆第9.2.1节中的结果，我们得到斜率参数的最大似然估计为：

 $$
\theta_{\text{ML}} = (X^\top X)^{-1} X^\top y = \frac{X^\top y}{X^\top X} \in \mathbb{R} \tag{9.66}
$$

其中， $ X = [x_1, \ldots, x_N]^\top \in \mathbb{R}^N $ ， $ y = [y_1, \ldots, y_N]^\top \in \mathbb{R}^N $ 。这意味着对于训练输入  $ X $ ，我们得到训练目标的最佳（最大似然）重构为：

 $$
X \theta_{\text{ML}} = X \left( \frac{X^\top y}{X^\top X} \right) = \frac{X X^\top}{X^\top X} y \tag{9.67}
$$

即，我们得到了  $ y $  和  $ X \theta $  之间最小二乘误差的近似值。由于我们正在寻找  $ y = X \theta $  的解，因此我们可以将线性回归视为求解线性方程组的问题。因此，我们可以联系到我们在第2章和第3章中讨论的线性代数和解析几何的概念。仔细观察式(9.67)，我们发现最大似然估计  $ \theta_{\text{ML}} $  在我们的例子（式(9.65)）中实际上是对  $ y $  进行正交投影，将其投影到由  $ X $  张成的一维子空间上。回忆第3.8节中关于正交投影的结果，我们识别出  $ \frac{X X^\top}{X^\top X} $  是投影矩阵， $ \theta_{\text{ML}} $  是投影到  $ \mathbb{R}^N $  中由  $ X $  张成的一维子空间上的坐标，而  $ X \theta_{\text{ML}} $  是  $ y $  到这个子空间的正交投影。因此，最大似然解还通过正交投影提供了一个几何最优解，通过找到子空间中“最接近”对应观测值  $ y $  的向量，其中“最接近”意味着函数值  $ y_n $  与  $ x_n \theta $ 之间的最小（平方）距离。这是通过正交投影实现的。图9.12(b)展示了将噪声观测值投影到最小化原始数据集及其投影（注意  $ x $  坐标是固定的）之间的平方距离的子空间上，这对应于最大似然解。

![图9.12](# "Geometric interpretation of least squares.")
*图9.12 最小二乘法的几何解释。 (a) 数据集；(b) 最大似然解被解释为一个投影。*

在一般线性回归情况下，其中

 $$
y = \phi(x)^\top \theta + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2) \tag{9.68}
$$

具有向量值特征  $ \phi(x) \in \mathbb{R}^K $ ，我们同样可以将最大似然结果

 $$
y \approx \Phi \theta_{\text{ML}}, \quad \theta_{\text{ML}} = (\Phi^\top \Phi)^{-1} \Phi^\top y \tag{9.70}
$$

解释为投影到由特征矩阵  $ \Phi $  的列张成的  $ K $ 维子空间  $ \mathbb{R}^N $  上；见第3.8.2节。如果我们在构建特征矩阵  $ \Phi $  时使用的特征函数  $ \phi_k $  是正交的（见第3.7节），那么我们得到一个特殊情况，其中  $ \Phi $  的列形成了一个正交基（见第3.5节），使得  $ \Phi^\top \Phi = I $ 。这将导致投影

 $$
\Phi (\Phi^\top \Phi)^{-1} \Phi^\top y = \Phi \Phi^\top y = \left( \sum_{k=1}^K \phi_k \phi_k^\top \right) y \tag{9.71}
$$

因此，最大似然投影仅仅是将  $ y $  投影到各个基向量  $ \phi_k $  上的和，即  $ \Phi $  的列。此外，由于基的正交性，不同特征之间的耦合消失了。在信号处理中，许多流行的基函数，如小波和傅里叶基，都是正交基函数。

**注释**。当基不是正交的，可以使用格拉姆-施密特过程（见第3.8.3节和Strang, 2003）将一组线性独立的基函数转换为正交基。
